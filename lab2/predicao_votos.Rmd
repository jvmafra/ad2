---
title: "Predição de votos dos deputados"
author: "João Victor Barroso Mafra"
date: "11 de dezembro de 2017"
output: html_document
---

```{r}
library(tidyr)
library(dplyr)
library(ggplot2)
library(readr)
library(caret)
library(elasticnet)
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(825)
```

ANALISANDO OS DADOS INICIAIS:

Observando a distribuição dos votos através de um boxplot, podemos ver que existe um outlier, ou seja, um deputado que obteve muito mais votos que os demais, e isso pode acabar prejudicando a construção de nossos modelos.

```{r}
eleicoes2014 <- read.csv("~/workspace/ad2/lab2/eleicoes2014.csv", encoding = "latin1") %>% select(-cargo)

boxplot(eleicoes2014$votos)
```

Assim, será eliminado o deputado que é outlier e ainda variáveis que não influenciam na quantidade de votos de algum parlamentar (id do candidato, seu nome e seu número), assim como variáveis cuja maioria das linhas é composta por valores desconhecidos NA. Feito isso, iniciaremos de fato o treinamento dos modelos.

```{r}

eleicoes2014 <- eleicoes2014 %>% filter(nome != "CELSO UBIRAJARA RUSSOMANNO")

eleicoes2014.filtered <- eleicoes2014 %>% select(-sequencial_candidato, -nome, -numero_cadidato, -recursos_de_outros_candidatos.comites, -recursos_de_partidos, -recursos_de_pessoas_físicas, -recursos_de_pessoas_juridicas, -recursos_proprios, -setor_economico_receita, -setor_economico_despesa) 
```


#1. Usando todas as variáveis disponíveis, tune (usando validação cruzada): (i) um modelo de regressão Ridge, (ii) um modelo de regressão Lasso e (iii) um modelo KNN. Para os modelos de regressão linear, o parâmetro a ser tunado é o lambda (penalização dos coeficientes) e o KNN o número de vizinhos.

Para todos os modelos, foi utilizada a validação cruzada com 5 blocos. Em relação aos parâmetros a serem tunados, foram utlizados 10 candidatos (no caso da Regressão Ridge e do Lasso é o lâmbda e o no caso do KNN é o número de vizinhos).

REGRESSÃO RIDGE:

Usando a regressão ridge, o lâmbda escolhido foi 0.0421, com um RMSE obtido de 26081.

```{r}

set.seed(825)

fitControl <- trainControl(method = "cv",
                           number = 5)

ridge.model.cv <- train(votos ~ ., 
               data = eleicoes2014.filtered,
               method = "ridge",
               trControl = fitControl,
               tuneLength = 10,
               preProcess = c('scale', 'center'))

ridge.model.cv
```

REGRESSÃO LASSO:

Para o Lasso, o lâmbda escolhido foi de 0.3666, que apresentou um RMSE de 26062.97.

```{r}

set.seed(825)

lasso.model.cv <- train(votos ~ ., 
               data = eleicoes2014.filtered,
               method = "lasso",
               trControl = fitControl,
               tuneLength = 10,
               preProcess = c('scale', 'center'))

lasso.model.cv

```


REGRESSÃO KNN:

Para a regressão KNN, o número K dos melhores vizinhos escolhido foi 9, com um RMSE de 28117.28.

```{r}

set.seed(825)

knn.model.cv <- train(votos ~ ., 
               data = eleicoes2014.filtered,
               method = "knn",
               trControl = fitControl,
               tuneLength = 10,
               preProcess = c('scale', 'center'))

knn.model.cv

```

#2. Compare os três modelos em termos do erro RMSE de validação cruzada.

RMSE da Regressão Ridge: 26081;
RMSE da Regressão Lasso: 26062;
RMSE da Regressão KNN: 28160;

O modelo com menor erro quadrático médio foi o gerado pela Regressão Lasso. Em seguida, com um erro muito próximo, vem o modelo gerado pelo Ridge e por último, o modelo gerado pela Regressão KNN, com erro quadrático médio maior que os outros dois.

#3. Quais as variáveis mais importantes segundo o modelo de regressão Ridge e Lasso?  Variáveis foram descartadas pelo Lasso? Quais?

Os dois modelos nos fornecem o mesmo resultado para a importância das variáveis. Temos que as mais importantes foram o total da receita do candidato (com overall igual a 100) e o total de despesas do mesmo (com overall igual a 97). Em seguida, um pouco mais distantes das duas primeiras, aparecem a quantidade de despesas (com overall 57) e a quantidade de doações que o deputado recebeu (overall igual a 51).

```{r}
ggplot(varImp(ridge.model.cv)) +
  geom_bar(stat="identity") +
  labs(title="Importância das variáveis usando Ridge", y="Importância", x="Variável")
```

```{r}
ggplot(varImp(lasso.model.cv)) +
  geom_bar(stat="identity") +
  labs(title="Importância das variáveis usando Lasso", y="Importância", x="Variável")
```

Analisando os coeficientes gerados no Lasso, temos que os com valor 0 são eliminados por ele. Abaixo, temos as variáveis descartadas pelo modelo. Para variáveis categóricas, o modelo gera uma nova variável para cada nível, por isso temos a presença de variáveis como partidoPCB e grauLÊ E ESCREVE.

```{r}
coefficients.lasso <- predict.enet(lasso.model.cv$finalModel, type='coefficients', s=lasso.model.cv$bestTune$fraction, mode='fraction')$coefficients

coefficients.lasso.model <- as.data.frame(coefficients.lasso)

coefficients.lasso.model <- data.frame(variavel=rownames(coefficients.lasso.model), coeficiente=coefficients.lasso)

coefficients.lasso.model.filtered <- coefficients.lasso.model %>% filter(coeficiente == 0)

coefficients.lasso.model.filtered
```


#4.Re-treine o melhor modelo (usando os melhores valores de parâmetros encontrados em todos os dados, sem usar validação cruzada). 

O modelo encontrado com o menor RMSE foi o gerado pelo Lasso. Retreinando o modelo, 

```{r}

lambdaGrid <- expand.grid(lambda = 0.0421)

set.seed(825)

lasso.fit <- train(votos ~ ., 
               data = eleicoes2014.filtered,
               method = "lasso",
               tuneGrid = lambdaGrid,
               preProcess = c('scale', 'center'))

lasso.fit


```











