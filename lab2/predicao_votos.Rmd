---
title: "Predição de votos dos deputados"
author: "João Victor Barroso Mafra"
date: "11 de dezembro de 2017"
output: html_document
---

```{r}
library(tidyr)
library(dplyr)
library(ggplot2)
library(readr)
library(caret)
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(825)
```




```{r}
eleicoes2014 <- read.csv("~/workspace/ad2/lab2/eleicoes2014.csv", encoding = "latin1") %>% select(-cargo)

eleicoes2014.filtered <- eleicoes2014 %>% select(-sequencial_candidato, -nome, -numero_cadidato, -recursos_de_outros_candidatos.comites, -recursos_de_partidos, -recursos_de_pessoas_físicas, -recursos_de_pessoas_juridicas, -recursos_proprios, -setor_economico_receita, -setor_economico_despesa)
```


#1. Usando todas as variáveis disponíveis, tune (usando validação cruzada): (i) um modelo de regressão Ridge, (ii) um modelo de regressão Lasso e (iii) um modelo KNN. Para os modelos de regressão linear, o parâmetro a ser tunado é o lambda (penalização dos coeficientes) e o KNN o número de vizinhos.

Para todos os modelos, foi utilizada a validação cruzada com 5 blocos. Em relação aos parâmetros a serem tunados, foram utlizados 10 candidatos (no caso da Regressão Ridge e do Lasso é o lâmbda e o no caso do KNN é o número de vizinhos).

REGRESSÃO RIDGE:

Usando a regressão ridge, o lâmbda escolhido foi 0.0421, com um RMSE obtido de 31753.45

```{r}

set.seed(825)

fitControl <- trainControl(method = "cv",
                           number = 5)

ridge.model.cv <- train(votos ~ ., 
               data = eleicoes2014.filtered,
               method = "ridge",
               trControl = fitControl,
               tuneLength = 10,
               preProcess = c('scale', 'center'))

ridge.model.cv
```

REGRESSÃO LASSO:

Para o Lasso, o lâmbda escolhido foi de 0.2777, que apresentou um RMSE de 31934.46.

```{r}

set.seed(825)

lasso.model.cv <- train(votos ~ ., 
               data = eleicoes2014.filtered,
               method = "lasso",
               trControl = fitControl,
               tuneLength = 10,
               preProcess = c('scale', 'center'))

lasso.model.cv

```


REGRESSÃO KNN:

Para a regressão KNN, o número K dos melhores vizinhos escolhido foi 15, com um RMSE de 33998.43.

```{r}

set.seed(825)

knn.model.cv <- train(votos ~ ., 
               data = eleicoes2014.filtered,
               method = "knn",
               trControl = fitControl,
               tuneLength = 10,
               preProcess = c('scale', 'center'))

knn.model.cv

```

#2. Compare os três modelos em termos do erro RMSE de validação cruzada.

RMSE da Regressão Ridge: 31753
RMSE da Regressão Lasso: 31934
RMSE da Regressão KNN: 33998

O modelo com menor erro quadrático médio foi o gerado pela Regressão Ridge. Em seguida, com um erro não tão maior, vem o modelo gerado pelo Lasso e por último, o modelo gerado pela Regressão KNN, com erro quadrático médio maior que os outros dois.

#3. Quais as variáveis mais importantes segundo o modelo de regressão Ridge e Lasso?  Variáveis foram descartadas pelo Lasso? Quais?

Analisando primeiramente o modelo de regressão Ridge, temos que as variáveis mais importantes foram o total da receita do candidato (com overaal igual a 100) e o total de despesas do mesmo ( com overall igual a 97). Em seguida, um pouco mais distantes das duas primeiras, aparecem a quantidade de despesas (com overall 63) e a quantidade de doações que o deputado recebeu (overall igual a 49).

```{r}
ggplot(varImp(ridge.model.cv)) +
  geom_bar(stat="identity") +
  labs(title="Importância das variáveis usando Ridge", y="Importância", x="Variável")
```

```{r}
predict.enet(lasso.model.cv$finalModel, type='coefficients', s=lasso.model.cv$bestTune$fraction, mode='fraction')
```









