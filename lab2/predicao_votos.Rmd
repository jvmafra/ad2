---
title: "Predição de votos dos deputados"
author: "João Victor Barroso Mafra"
date: "11 de dezembro de 2017"
output: html_document
---

```{r}
library(tidyr)
library(dplyr)
library(ggplot2)
library(readr)
library(caret)
library(elasticnet)
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(895)
```

ANALISANDO OS DADOS INICIAIS:

Observando a distribuição dos votos através de um boxplot, podemos ver que existe um outlier, ou seja, um deputado que obteve muito mais votos que os demais, e isso pode acabar prejudicando a construção de nossos modelos.

```{r}
eleicoes2014 <- read.csv("~/workspace/ad2/lab2/eleicoes2014.csv", encoding = "latin1") %>% select(-cargo)

boxplot(eleicoes2014$votos)
```

Assim, será eliminado o deputado que é outlier e ainda variáveis que não influenciam na quantidade de votos de algum parlamentar (id do candidato, seu nome e seu número), assim como variáveis cuja maioria das linhas é composta por valores desconhecidos NA. Feito isso, iniciaremos de fato o treinamento dos modelos.

```{r}

eleicoes2014 <- eleicoes2014 %>% filter(nome != "CELSO UBIRAJARA RUSSOMANNO")

eleicoes2014.filtered <- eleicoes2014 %>% select(-sequencial_candidato, -nome, -numero_cadidato, -recursos_de_outros_candidatos.comites, -recursos_de_partidos, -recursos_de_pessoas_físicas, -recursos_de_pessoas_juridicas, -recursos_proprios, -setor_economico_receita, -setor_economico_despesa) 
```


#1. Usando todas as variáveis disponíveis, tune (usando validação cruzada): (i) um modelo de regressão Ridge, (ii) um modelo de regressão Lasso e (iii) um modelo KNN. Para os modelos de regressão linear, o parâmetro a ser tunado é o lambda (penalização dos coeficientes) e o KNN o número de vizinhos.

Para todos os modelos, foi utilizada a validação cruzada com 5 blocos. Em relação aos parâmetros a serem tunados, foram utlizados 10 candidatos (no caso da Regressão Ridge e do Lasso é o lâmbda e o no caso do KNN é o número de vizinhos).

REGRESSÃO RIDGE:

Usando a regressão ridge, o lâmbda escolhido foi 0.00023, com um RMSE obtido de 25697.93.

```{r}

set.seed(895)

fitControl <- trainControl(method = "cv",
                           number = 5)

ridge.model.cv <- train(votos ~ ., 
               data = eleicoes2014.filtered,
               method = "ridge",
               trControl = fitControl,
               tuneLength = 10,
               preProcess = c('scale', 'center'))

ridge.model.cv
```

REGRESSÃO LASSO:

Para o Lasso, o lâmbda escolhido foi de 0.9, que apresentou um RMSE de 25699.33.

```{r}

set.seed(895)

lasso.model.cv <- train(votos ~ ., 
               data = eleicoes2014.filtered,
               method = "lasso",
               trControl = fitControl,
               tuneLength = 10,
               preProcess = c('scale', 'center'))

lasso.model.cv

```


REGRESSÃO KNN:

Para a regressão KNN, o número K dos melhores vizinhos escolhido foi 13, com um RMSE de 28121.94.

```{r}

set.seed(895)

knn.model.cv <- train(votos ~ ., 
               data = eleicoes2014.filtered,
               method = "knn",
               trControl = fitControl,
               tuneLength = 10,
               preProcess = c('scale', 'center'))

knn.model.cv

```

#2. Compare os três modelos em termos do erro RMSE de validação cruzada.

RMSE da Regressão Ridge: 25697;
RMSE da Regressão Lasso: 25699;
RMSE da Regressão KNN: 28121;

O modelo com menor erro quadrático médio foi o gerado pela Regressão Ridge. Em seguida, com um erro muito próximo, vem o modelo gerado pelo Lasso e por último, o modelo gerado pela Regressão KNN, com erro quadrático médio maior que os outros dois.

#3. Quais as variáveis mais importantes segundo o modelo de regressão Ridge e Lasso?  Variáveis foram descartadas pelo Lasso? Quais?

Os dois modelos nos fornecem o mesmo resultado para a importância das variáveis. Temos que as mais importantes foram o total da receita do candidato (com overall igual a 100) e o total de despesas do mesmo (com overall igual a 97). Em seguida, um pouco mais distante das duas primeiras, aparecem a quantidade de despesas (com overall 57) e a quantidade de doações que o deputado recebeu (overall igual a 51).

```{r}
ggplot(varImp(ridge.model.cv)) +
  geom_bar(stat="identity") +
  labs(title="Importância das variáveis usando Ridge", y="Importância", x="Variável")
```

```{r}
ggplot(varImp(lasso.model.cv)) +
  geom_bar(stat="identity") +
  labs(title="Importância das variáveis usando Lasso", y="Importância", x="Variável")
```

No Lasso, os coeficientes com valor 0 são eliminados por ele. Como podemos ver abaixo, nenhuma variável foi descartada pelo modelo.

```{r}
coefficients.lasso <- predict.enet(lasso.model.cv$finalModel, type='coefficients', s=lasso.model.cv$bestTune$fraction, mode='fraction')$coefficients

coefficients.lasso.model <- as.data.frame(coefficients.lasso)

coefficients.lasso.model <- data.frame(variavel=rownames(coefficients.lasso.model), coeficiente=coefficients.lasso)

coefficients.lasso.model.filtered <- coefficients.lasso.model %>% filter(coeficiente == 0)

coefficients.lasso.model.filtered
```


#4.Re-treine o melhor modelo (usando os melhores valores de parâmetros encontrados em todos os dados, sem usar validação cruzada). 

O modelo encontrado com o menor RMSE foi o gerado pelo Ridge, com parâmetro lâmbda igual a 0.00023. Vamos usar isso para re-treinar o modelo. O RMSE obtido foi de 26449.

```{r}

lambdaGrid <- expand.grid(lambda = 0.0002371374)

set.seed(825)

ridge.fit <- train(votos ~ ., 
               data = eleicoes2014.filtered,
               method = "ridge",
               tuneLength = 30,
               trControl = fitControl <- trainControl(method = "cv", number =10),
               preProcess = c('scale', 'center'))

ridge.fit


```


Melhorando o modelo gerado usando outro método:

Usando agora o método PLS (Partial least squares), vamos fazer um novo treinamento. O RMSE observado foi de 25704, ou seja, obtivemos um desempenho melhor que o modelo gerado pela regressão ridge.

```{r}
set.seed(895)

pls.fit <- train(votos ~ ., 
               data = eleicoes2014.filtered,
               method = "pls",
               trControl = fitControl <- trainControl(method = "cv", number =12),
               tuneLength = 25,
               preProcess = c('scale', 'center'))

pls.fit

```


#5.Use esse último modelo treinado para prever os dados de teste disponíveis no challenge que criamos na plataforma Kaggle.


Usando um arquivo de teste, vamos realizar inicialmente as predições usando o modelo ridge com o melhor lâmbda encontrado inicialmente.


```{r}
test.df <- read.csv("~/workspace/ad2/lab2/test.csv", encoding = "UTF-8")


predictions <- predict(ridge.fit, test.df)

df.to.submission <- data.frame(ID = test.df$ID, votos = predictions)

df.to.submission <- apply(df.to.submission, 2, function(x) {ifelse(x < 0, 0, x)}) 

write.csv(df.to.submission, "jv_submission_ridge_fit_3.csv", row.names = FALSE)
```


Agora, realizando as predições usando o modelo gerado pelo método PLS.

```{r}
predictions.pls <- predict(pls.fit, test.df)

df.to.submission.pls <- data.frame(ID = test.df$ID, votos = predictions.pls)

df.to.submission.pls <- apply(df.to.submission.pls, 2, function(x) {ifelse(x < 0, 0, x)}) 

write.csv(df.to.submission.pls, "jv_submission_pls_cv_12.csv", row.names = FALSE)
```


Apesar do PLS ter apresentado menor RMSE no treino, o modelo gerado pela regressão Ridge obteve, a priori, um score melhor no teste na plataforma Kaggle.












